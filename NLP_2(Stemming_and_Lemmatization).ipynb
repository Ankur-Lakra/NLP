{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7NCL3mfZkngE",
        "outputId": "c3b5fd10-cba4-4092-9755-94273de0905f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'write'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#Porter stemming\n",
        "from nltk.stem import PorterStemmer\n",
        "porter=PorterStemmer()\n",
        "porter.stem('writing')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lacanster stemming\n",
        "from nltk.stem import LancasterStemmer\n",
        "lacanster=LancasterStemmer()\n",
        "lacanster.stem('sweets')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MBVqJ-pBktcS",
        "outputId": "c808b312-3625-4306-d1c3-6f55e0ceb078"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sweet'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lacanster.stem('reading')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fFXnXJb0kv6Q",
        "outputId": "e2829431-74ef-4043-86fa-4525b3f87991"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'read'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Regexp Stemming\n",
        "from nltk.stem import RegexpStemmer\n",
        "stemming_word_reg=RegexpStemmer('ing')\n",
        "stemming_word_reg.stem('reading')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "B3oCI9qakxgg",
        "outputId": "85a4a455-bb28-48fe-88f7-42402f6d6d7e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'read'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Snowball Stemming\n",
        "from nltk.stem import SnowballStemmer\n",
        "SnowballStemmer.languages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcAEqLo3kzGR",
        "outputId": "e6eb73ac-fc63-48e6-e9d6-3c44c2dda3f6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('arabic',\n",
              " 'danish',\n",
              " 'dutch',\n",
              " 'english',\n",
              " 'finnish',\n",
              " 'french',\n",
              " 'german',\n",
              " 'hungarian',\n",
              " 'italian',\n",
              " 'norwegian',\n",
              " 'porter',\n",
              " 'portuguese',\n",
              " 'romanian',\n",
              " 'russian',\n",
              " 'spanish',\n",
              " 'swedish')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lang_french=SnowballStemmer('french')\n",
        "lang_french.stem('bonjoura')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6Ejj3s2Yk1Zy",
        "outputId": "11c773db-7d1d-4d67-8088-29be2cb2c585"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bonjour'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Word Lemmatizer\n",
        "!python -m nltk.downloader wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "ex_lemma=WordNetLemmatizer()\n",
        "ex_lemma.lemmatize('plays')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "_bC3p4uAk3Pr",
        "outputId": "72eda4c8-bc25-4774-ed7a-5831f34d838c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'play'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex_lemma.lemmatize('driving')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nbXC6dKJk47Z",
        "outputId": "a7cae965-c059-48d1-98bc-a225f79b72cd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'driving'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spacy Lemmatizer v Porter Stemming"
      ],
      "metadata": {
        "id": "zahr6N2gk8QS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Spacy Lemmatizer\n",
        "import spacy\n",
        "sp = spacy.load('en_core_web_sm')\n",
        "text = \"Where there is a wills there is a ways.\"\n",
        "doc = sp(text)\n",
        "lemmatized_tokens = [token.lemma_ for token in doc]\n",
        "lemmatized_text = ' '.join(lemmatized_tokens)"
      ],
      "metadata": {
        "id": "_yhQ30lXk9qq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lemmatized_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "285Exmuck_gR",
        "outputId": "f2f9b859-c4ab-4f92-9099-b783b30c9b58"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "where there be a will there be a way .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize\n",
        "tokenized_words=word_tokenize(text)\n",
        "print(tokenized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iw6k0aDClBzq",
        "outputId": "572738b5-fe94-4fe8-c294-fb3e3767c70e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Where', 'there', 'is', 'a', 'wills', 'there', 'is', 'a', 'ways', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentence = []\n",
        "for word in tokenized_words:\n",
        "    tokenized_sentence.append(porter.stem(word))\n",
        "tokenized_sentence = \" \".join(tokenized_sentence)\n",
        "tokenized_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FHn2FS_8lErC",
        "outputId": "699ed545-86c0-464a-cc0b-1adb1985458f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'where there is a will there is a way .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}